# Dual Encoder as a Retriever for Large Language Models (LLMs)

## Overview
This repository provides a detailed implementation of a **Dual Encoder architecture** designed for question-answering (Q&A) and retrieval tasks, specifically in the context of **Retrieval-Augmented Generation (RAG)** applications. The core components of RAG—**the Large Language Model (LLM)** and **the retriever**—are both critical to achieving optimal results. Below, we describe the key aspects of the RAG setup and the role of the retriever, particularly the Dual Encoder model used in this project.

## 1. Vanilla RAG

In a basic **RAG application**, the two most important components are:

- **LLM**: Responsible for generating answers based on the prompt and provided context.
- **Retriever**: Responsible for retrieving the top-**k** most relevant chunks of information, which are appended to the LLM's context for generating more informed responses.

The retriever fetches the most relevant chunks of text based on the input prompt and enhances the LLM’s response by providing additional contextual information. The LLM, in turn, uses this context alongside the prompt to generate its inference.

## 2. The Retriever

The **retriever** plays a pivotal role in determining the output quality of the LLM. A poorly designed retriever can lead to suboptimal responses or even **hallucinations** (incorrect or misleading information generated by the LLM). As such, the **selection or design** of a high-quality retriever model is essential before attempting to develop RAG-based systems.

This repository includes a robust **Dual Encoder** architecture, which can be utilized to build a highly effective retriever model for Q&A tasks and more.

## 3. About the Dual Encoder Retriever

The **Dual Encoder** utilizes two **BERT-based encoders**:

- One encoder processes the **prompt** (question).
- The second encoder processes the **answer(s)** or chunks of text (in retrieval tasks).

This architecture leverages a clever application of **cross-entropy loss** to assign higher scores to more relevant answers, allowing the model to learn and improve its retrieval capabilities over time. The result is a retriever that can effectively identify and return the best possible answers for a given question.

## 4. Installation 

To install the necessary dependencies, run:

```bash
pip install -r requirements.txt
```



---
